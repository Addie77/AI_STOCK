import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV # [æ–°å¢] è‡ªå‹•èª¿åƒå·¥å…·
from src.strategy import calculate_rsi, calculate_macd

def prepare_features(df):
    """
    ç‰¹å¾µå·¥ç¨‹å‡ç´šç‰ˆï¼šåŠ å…¥æ­·å²æ•¸æ“š (Lag Features)
    """
    df = df.copy()
    
    # --- 1. åŸºç¤æŠ€è¡“æŒ‡æ¨™ ---
    df['RSI'] = calculate_rsi(df['Close'])
    macd, signal, hist = calculate_macd(df['Close'])
    df['MACD_Hist'] = hist
    
    df['MA20'] = df['Close'].rolling(window=20).mean()
    df['Bias_20'] = (df['Close'] - df['MA20']) / df['MA20'].replace(0, np.nan)
    df['Vol_Change'] = df['Volume'].pct_change()
    
    # --- 2. [æ–°å¢] æ­·å²ç‰¹å¾µ (Lag Features) ---
    # è®“ AI çŸ¥é“ã€Œæ˜¨å¤©ã€å’Œã€Œå‰å¤©ã€ç™¼ç”Ÿä»€éº¼äº‹
    # Lag 1 = æ˜¨å¤©, Lag 2 = å‰å¤©
    
    # æ˜¨å¤©çš„æ¼²è·Œå¹…
    df['Return'] = df['Close'].pct_change()
    df['Return_Lag1'] = df['Return'].shift(1)
    df['Return_Lag2'] = df['Return'].shift(2)
    
    # æ˜¨å¤©çš„æˆäº¤é‡è®ŠåŒ–
    df['Vol_Change_Lag1'] = df['Vol_Change'].shift(1)
    
    # æ˜¨å¤©çš„ RSI
    df['RSI_Lag1'] = df['RSI'].shift(1)
    
    # --- 3. é æ¸¬ç›®æ¨™ ---
    df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)
    
    # --- 4. æ¸…æ´—è³‡æ–™ ---
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df = df.dropna()
    
    return df

def predict_next_day(df):
    """
    å‡ç´šç‰ˆé æ¸¬ï¼šä½¿ç”¨ GridSearchCV å°‹æ‰¾æœ€ä½³åƒæ•¸
    """
    # å› ç‚ºåŠ äº† Lag Featuresï¼Œå‰é¢æœƒå¤šå‡ºå¹¾å¤© NaNï¼Œæ‰€ä»¥è³‡æ–™é•·åº¦è¦æ±‚è¦æ›´é«˜
    if len(df) < 100:
        return None

    try:
        data = prepare_features(df)
        
        if len(data) < 60:
            return None
        
        # å®šç¾©ç‰¹å¾µæ¬„ä½ (åŠ å…¥æ–°çš„ Lag ç‰¹å¾µ)
        feature_cols = [
            'RSI', 'MACD_Hist', 'Bias_20', 'Vol_Change',
            'Return_Lag1', 'Return_Lag2', # æ˜¨å¤©çš„æ¼²å¹…ã€å‰å¤©çš„æ¼²å¹…
            'Vol_Change_Lag1', 'RSI_Lag1' # æ˜¨å¤©çš„é‡ã€æ˜¨å¤©çš„RSI
        ]
        
        X = data[feature_cols]
        y = data['Target']
        
        # åˆ‡åˆ†è¨“ç·´é›†èˆ‡é æ¸¬é›†
        X_train = X.iloc[:-1]
        y_train = y.iloc[:-1]
        X_new = X.iloc[[-1]] 
        
        # --- [æ–°å¢] è‡ªå‹•åƒæ•¸èª¿æ•´ (Grid Search) ---
        # å‘Šè¨´é›»è…¦è©¦è©¦çœ‹é€™äº›çµ„åˆï¼Œæ‰¾å‡ºé€™æ”¯è‚¡ç¥¨æœ€é©åˆçš„åƒæ•¸
        param_grid = {
            'n_estimators': [50, 100, 200],      # æ¨¹çš„æ•¸é‡
            'max_depth': [3, 5, 10],             # æ¨¹çš„æ·±åº¦ (å¤ªæ·±æœƒæ­»èƒŒï¼Œå¤ªæ·ºå­¸ä¸æœƒ)
            'min_samples_split': [2, 5]          # ç¯€é»åˆ†å‰²æœ€å°æ¨£æœ¬æ•¸
        }
        
        rf = RandomForestClassifier(random_state=42)
        
        # cv=3 ä»£è¡¨åš 3 æ¬¡äº¤å‰é©—è­‰ (Cross Validation)
        grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1)
        
        # é–‹å§‹è¨“ç·´ (é€™ä¸€æ­¥æœƒæ¯”è¼ƒä¹…ä¸€é»ï¼Œå› ç‚ºå®ƒåœ¨ç‹‚è©¦åƒæ•¸)
        grid_search.fit(X_train, y_train)
        
        # å–å¾—æœ€å¼·æ¨¡å‹
        best_model = grid_search.best_estimator_
        
        # --- å°å‡ºç‰¹å¾µé‡è¦æ€§ (ç”¨æœ€å¼·æ¨¡å‹çœ‹) ---
        print(f"\nğŸ§  [AI æœ€ä½³åƒæ•¸] {grid_search.best_params_}")
        print("ğŸ“Š [AI æœ€çœ‹é‡æŒ‡æ¨™]")
        importances = best_model.feature_importances_
        indices = np.argsort(importances)[::-1]
        
        for i in indices:
            print(f"   ğŸ”¹ {feature_cols[i]}: {importances[i]:.4f}")
        print("-" * 30)
        
        # é æ¸¬
        probs = best_model.predict_proba(X_new)[0]
        up_prob = round(probs[1] * 100, 1) 
        
        return up_prob
        
    except Exception as e:
        print(f"âŒ ML é æ¸¬å¤±æ•—: {e}")
        return None