import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
#from sklearn.model_selection import GridSearchCV # [æ–°å¢] è‡ªå‹•èª¿åƒå·¥å…·
from src.strategy import calculate_rsi, calculate_macd

def prepare_features(df):
    """
    ç‰¹å¾µå·¥ç¨‹å‡ç´šç‰ˆï¼šåŠ å…¥æ­·å²æ•¸æ“š (Lag Features)
    """
    df = df.copy()
    
    # --- 1. åŸºç¤æŠ€è¡“æŒ‡æ¨™ ---
    df['RSI'] = calculate_rsi(df['Close'])
    macd, signal, hist = calculate_macd(df['Close'])
    df['MACD_Hist'] = hist
    
    df['MA20'] = df['Close'].rolling(window=20).mean()
    df['Bias_20'] = (df['Close'] - df['MA20']) / df['MA20'].replace(0, np.nan)
    df['Vol_Change'] = df['Volume'].pct_change()
    
    # --- 2. [æ–°å¢] æ­·å²ç‰¹å¾µ (Lag Features) ---
    # è®“ AI çŸ¥é“ã€Œæ˜¨å¤©ã€å’Œã€Œå‰å¤©ã€ç™¼ç”Ÿä»€éº¼äº‹
    # Lag 1 = æ˜¨å¤©, Lag 2 = å‰å¤©
    
    # æ˜¨å¤©çš„æ¼²è·Œå¹…
    df['Return'] = df['Close'].pct_change()
    df['Return_Lag1'] = df['Return'].shift(1)
    df['Return_Lag2'] = df['Return'].shift(2)
    
    # æ˜¨å¤©çš„æˆäº¤é‡è®ŠåŒ–
    df['Vol_Change_Lag1'] = df['Vol_Change'].shift(1)
    
    # æ˜¨å¤©çš„ RSI
    df['RSI_Lag1'] = df['RSI'].shift(1)
    
    # --- 3. é æ¸¬ç›®æ¨™ ---
    df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)
    
    # --- 4. æ¸…æ´—è³‡æ–™ ---
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df = df.dropna()
    
    return df

def predict_next_day(df):
    """
    â˜ï¸ é›²ç«¯è¼•é‡ç‰ˆé æ¸¬ï¼šå°ˆç‚º Render å…è²»ç‰ˆå„ªåŒ–
    ç§»é™¤ GridSearchCV èˆ‡å¤šåŸ·è¡Œç·’ï¼Œç¢ºä¿ä¸æœƒå› è¨˜æ†¶é«”ä¸è¶³è€Œç•¶æ©Ÿã€‚
    """
    # 1. è³‡æ–™é•·åº¦æª¢æŸ¥
    if len(df) < 100:
        return None

    try:
        # å‡è¨­ä½ æœ‰å®šç¾© prepare_features å‡½å¼
        data = prepare_features(df)
        
        # æº–å‚™å¥½è³‡æ–™å¾Œï¼Œå†æ¬¡æª¢æŸ¥é•·åº¦ (å› ç‚º Lag ç‰¹å¾µæœƒç”¢ç”Ÿ NaN è¢«åˆªé™¤)
        if len(data) < 60:
            return None
        
        # 2. å®šç¾©ç‰¹å¾µæ¬„ä½ (ä¿ç•™ä½ åŸæœ¬çš„è¨­è¨ˆ)
        feature_cols = [
            'RSI', 'MACD_Hist', 'Bias_20', 'Vol_Change',
            'Return_Lag1', 'Return_Lag2', # æ˜¨å¤©çš„æ¼²å¹…ã€å‰å¤©çš„æ¼²å¹…
            'Vol_Change_Lag1', 'RSI_Lag1' # æ˜¨å¤©çš„é‡ã€æ˜¨å¤©çš„RSI
        ]
        
        # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰æ¬„ä½éƒ½å­˜åœ¨
        missing_cols = [col for col in feature_cols if col not in data.columns]
        if missing_cols:
            print(f"âš ï¸ ç¼ºå°‘ç‰¹å¾µæ¬„ä½: {missing_cols}")
            return None

        X = data[feature_cols]
        y = data['Target']
        
        # 3. åˆ‡åˆ†è¨“ç·´é›†èˆ‡é æ¸¬é›†
        X_train = X.iloc[:-1]
        y_train = y.iloc[:-1]
        X_new = X.iloc[[-1]] 
        
        # ======================================================
        # ğŸ”¥ã€é—œéµä¿®æ”¹ã€‘é›²ç«¯ç”Ÿå­˜æ¨¡å¼
        # ======================================================
        
        # ä¸å†ä½¿ç”¨ GridSearch äº‚æ§æ‰“é³¥ï¼Œç›´æ¥æŒ‡å®šä¸€çµ„ç©©å®šçš„åƒæ•¸
        model = RandomForestClassifier(
            n_estimators=30,     # æ¨¹ç¨® 30 æ£µå°±å¥½ (åŸæœ¬å¯èƒ½é è¨­ 100)
            max_depth=5,         # æ¨¹é«˜é™åˆ¶ 5 å±¤ (é¿å…éåº¦æ“¬åˆ + çœè¨˜æ†¶é«”)
            min_samples_split=5, # ç¨å¾®ä¿å®ˆä¸€é»çš„åˆ†è£‚
            n_jobs=1,            # ã€æ•‘å‘½é—œéµã€‘å¼·åˆ¶å–®æ ¸å¿ƒï¼çµ•å°ä¸èƒ½ç”¨ -1
            random_state=42
        )
        
        # ç›´æ¥è¨“ç·´ä¸€æ¬¡ (åŸæœ¬è¦è¨“ç·´ 54 æ¬¡)
        model.fit(X_train, y_train)
        
        # --- (é¸ç”¨) é‚„æ˜¯å¯ä»¥å°å‡ºç‰¹å¾µé‡è¦æ€§ï¼Œè®“ä½ è·Ÿæ•™æˆæœ‰æ±è¥¿è¬› ---
        # print("ğŸ“Š [AI æ¬Šé‡] " + ", ".join([f"{feature_cols[i]}:{model.feature_importances_[i]:.2f}" for i in np.argsort(model.feature_importances_)[::-1][:3]]))
        
        # 4. é æ¸¬
        probs = model.predict_proba(X_new)[0]
        up_prob = round(probs[1] * 100, 1) 
        
        return up_prob
        
    except Exception as e:
        print(f"âŒ ML é æ¸¬å¤±æ•— (è¨˜æ†¶é«”ä¿è­·æ¨¡å¼): {e}")
        # å›å‚³ None è®“å¤–å±¤å»è™•ç† (ä¾‹å¦‚é¡¯ç¤ºã€Œè³‡æ–™ä¸è¶³ã€)
        return None